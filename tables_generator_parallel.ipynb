{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# generate the three dataset"
   ],
   "metadata": {
    "id": "pw59LBcf8uzb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "!pip install pandarallel"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDbc9Ncp8mRV",
    "outputId": "d1306655-ade6-40c0-e074-e115ddd15a20",
    "ExecuteTime": {
     "end_time": "2024-02-07T11:48:23.851123Z",
     "start_time": "2024-02-07T11:48:22.445595Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandarallel in ./.venv/lib/python3.12/site-packages (1.6.5)\r\n",
      "Requirement already satisfied: dill>=0.3.1 in ./.venv/lib/python3.12/site-packages (from pandarallel) (0.3.8)\r\n",
      "Requirement already satisfied: pandas>=1 in ./.venv/lib/python3.12/site-packages (from pandarallel) (2.2.0)\r\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from pandarallel) (5.9.8)\r\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas>=1->pandarallel) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=1->pandarallel) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1->pandarallel) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1->pandarallel) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1->pandarallel) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "2jGfDIRk8JX8",
    "outputId": "9c7c8bad-0f07-424d-b233-112936aaaea7",
    "ExecuteTime": {
     "end_time": "2024-02-07T11:48:28.146126Z",
     "start_time": "2024-02-07T11:48:23.852121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to generate customer profiles table: 0.016s\n",
      "Time to generate terminal profiles table: 0.003s\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=125), Label(value='0 / 125'))), HB…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b0b0d4a02284e5f9b2a0697b1bed7f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to associate terminals to customers: 0.21s\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=125), Label(value='0 / 125'))), HB…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acfa47629549403da1e60301041aa5a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteorigat/PycharmProjects/new-generation-data-models-and-DBMSs-project/.venv/lib/python3.12/site-packages/pandarallel/data_types/dataframe_groupby.py:81: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return df_groupby._wrap_applied_output(*args, not_indexed_same=mutated)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to generate transactions: 1.2s\n",
      "Number of frauds from scenario 1: 91\n",
      "Number of frauds from scenario 2: 7927\n",
      "Number of frauds from scenario 3: 2174\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True, verbose=False)\n",
    "\n",
    "def generate_customer_profiles_table(n_customers, random_state=0):\n",
    "    np.random.seed(random_state)\n",
    "    customer_id_properties=[]\n",
    "\n",
    "    # Generate customer properties from random distributions\n",
    "    for customer_id in range(n_customers):\n",
    "        x_customer_id = np.random.uniform(0,100)\n",
    "        y_customer_id = np.random.uniform(0,100)\n",
    "\n",
    "        mean_amount = np.random.uniform(5,100) # Arbitrary (but sensible) value\n",
    "        std_amount = mean_amount/2 # Arbitrary (but sensible) value\n",
    "\n",
    "        mean_nb_tx_per_day = np.random.uniform(0,4) # Arbitrary (but sensible) value\n",
    "\n",
    "        customer_id_properties.append([customer_id,\n",
    "                                      x_customer_id, y_customer_id,\n",
    "                                      mean_amount, std_amount,\n",
    "                                      mean_nb_tx_per_day])\n",
    "\n",
    "    customer_profiles_table = pd.DataFrame(customer_id_properties, columns=['CUSTOMER_ID',\n",
    "                                                                      'x_customer_id', 'y_customer_id',\n",
    "                                                                      'mean_amount', 'std_amount',\n",
    "                                                                      'mean_nb_tx_per_day'])\n",
    "\n",
    "    return customer_profiles_table\n",
    "\n",
    "def generate_terminal_profiles_table(n_terminals, random_state=0):\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    terminal_id_properties=[]\n",
    "\n",
    "    # Generate terminal properties from random distributions\n",
    "    for terminal_id in range(n_terminals):\n",
    "\n",
    "        x_terminal_id = np.random.uniform(0,100)\n",
    "        y_terminal_id = np.random.uniform(0,100)\n",
    "\n",
    "        terminal_id_properties.append([terminal_id,\n",
    "                                      x_terminal_id, y_terminal_id])\n",
    "\n",
    "    terminal_profiles_table = pd.DataFrame(terminal_id_properties, columns=['TERMINAL_ID',\n",
    "                                                                      'x_terminal_id', 'y_terminal_id'])\n",
    "\n",
    "    return terminal_profiles_table\n",
    "\n",
    "def generate_dataset_parallel(n_customers, n_terminals, nb_days, start_date, r):\n",
    "    ## Speeds up computation significantly; On windows all functions used in parallel computations should be self-contained.\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import random\n",
    "\n",
    "    def get_list_terminals_within_radius(customer_profile, x_y_terminals, r):\n",
    "        x_y_customer = customer_profile[['x_customer_id','y_customer_id']].values.astype(float)\n",
    "        squared_diff_x_y = np.square(x_y_customer - x_y_terminals)\n",
    "        dist_x_y = np.sqrt(np.sum(squared_diff_x_y, axis=1))\n",
    "        available_terminals = list(np.where(dist_x_y<r)[0])\n",
    "        return available_terminals\n",
    "\n",
    "    def generate_transactions_table(customer_profile, start_date, nb_days):\n",
    "        customer_transactions = []\n",
    "        random.seed(int(customer_profile.CUSTOMER_ID))\n",
    "        np.random.seed(int(customer_profile.CUSTOMER_ID))\n",
    "        for day in range(nb_days):\n",
    "            nb_tx = np.random.poisson(customer_profile.mean_nb_tx_per_day)\n",
    "            if nb_tx>0:\n",
    "                for tx in range(nb_tx):\n",
    "                    time_tx = int(np.random.normal(86400/2, 20000))\n",
    "                    if (time_tx>0) and (time_tx<86400):\n",
    "                        amount = np.random.normal(customer_profile.mean_amount, customer_profile.std_amount)\n",
    "                        if amount<0:\n",
    "                            amount = np.random.uniform(0,customer_profile.mean_amount*2)\n",
    "                        amount=np.round(amount,decimals=2)\n",
    "                        if len(customer_profile.available_terminals)>0:\n",
    "                            terminal_id = random.choice(customer_profile.available_terminals)\n",
    "                            customer_transactions.append([time_tx+day*86400, day,\n",
    "                                                        customer_profile.CUSTOMER_ID,\n",
    "                                                        terminal_id, amount])\n",
    "        customer_transactions = pd.DataFrame(customer_transactions, columns=['TX_TIME_SECONDS', 'TX_TIME_DAYS', 'CUSTOMER_ID', 'TERMINAL_ID', 'TX_AMOUNT'])\n",
    "        if len(customer_transactions)>0:\n",
    "            customer_transactions['TX_DATETIME'] = pd.to_datetime(customer_transactions[\"TX_TIME_SECONDS\"], unit='s', origin=start_date)\n",
    "            customer_transactions=customer_transactions[['TX_DATETIME','CUSTOMER_ID', 'TERMINAL_ID', 'TX_AMOUNT','TX_TIME_SECONDS', 'TX_TIME_DAYS']]\n",
    "        return customer_transactions\n",
    "\n",
    "    start_time=time.time()\n",
    "    customer_profiles_table = generate_customer_profiles_table(n_customers, random_state = 0)\n",
    "    print(\"Time to generate customer profiles table: {0:.2}s\".format(time.time()-start_time))\n",
    "\n",
    "    start_time=time.time()\n",
    "    terminal_profiles_table = generate_terminal_profiles_table(n_terminals, random_state = 1)\n",
    "    print(\"Time to generate terminal profiles table: {0:.2}s\".format(time.time()-start_time))\n",
    "\n",
    "    start_time=time.time()\n",
    "    x_y_terminals = terminal_profiles_table[['x_terminal_id','y_terminal_id']].values.astype(float)\n",
    "    customer_profiles_table['available_terminals'] = customer_profiles_table.parallel_apply(lambda x : get_list_terminals_within_radius(x, x_y_terminals=x_y_terminals, r=r), axis=1)\n",
    "    customer_profiles_table['nb_terminals']=customer_profiles_table.available_terminals.apply(len)\n",
    "    print(\"Time to associate terminals to customers: {0:.2}s\".format(time.time()-start_time))\n",
    "\n",
    "    start_time=time.time()\n",
    "    transactions_df=customer_profiles_table.groupby('CUSTOMER_ID').parallel_apply(lambda x : generate_transactions_table(x.iloc[0], start_date=start_date, nb_days=nb_days)).reset_index(drop=True)\n",
    "    print(\"Time to generate transactions: {0:.2}s\".format(time.time()-start_time))\n",
    "\n",
    "    # Sort transactions chronologically\n",
    "    transactions_df=transactions_df.sort_values('TX_DATETIME')\n",
    "    # Reset indices, starting from 0\n",
    "    transactions_df.reset_index(inplace=True,drop=True)\n",
    "    transactions_df.reset_index(inplace=True)\n",
    "    # TRANSACTION_ID are the dataframe indices, starting from 0\n",
    "    transactions_df.rename(columns = {'index':'TRANSACTION_ID'}, inplace = True)\n",
    "\n",
    "    return (customer_profiles_table, terminal_profiles_table, transactions_df)\n",
    "\n",
    "def add_frauds(customer_profiles_table, terminal_profiles_table, transactions_df):\n",
    "\n",
    "    # By default, all transactions are genuine\n",
    "    transactions_df['TX_FRAUD']=0\n",
    "    transactions_df['TX_FRAUD_SCENARIO']=0\n",
    "\n",
    "    # Scenario 1\n",
    "    transactions_df.loc[transactions_df.TX_AMOUNT>220, 'TX_FRAUD']=1\n",
    "    transactions_df.loc[transactions_df.TX_AMOUNT>220, 'TX_FRAUD_SCENARIO']=1\n",
    "    nb_frauds_scenario_1=transactions_df.TX_FRAUD.sum()\n",
    "    print(\"Number of frauds from scenario 1: \"+str(nb_frauds_scenario_1))\n",
    "\n",
    "    # Scenario 2\n",
    "    for day in range(transactions_df.TX_TIME_DAYS.max()):\n",
    "\n",
    "        compromised_terminals = terminal_profiles_table.TERMINAL_ID.sample(n=2, random_state=day)\n",
    "\n",
    "        compromised_transactions=transactions_df[(transactions_df.TX_TIME_DAYS>=day) &\n",
    "                                                    (transactions_df.TX_TIME_DAYS<day+28) &\n",
    "                                                    (transactions_df.TERMINAL_ID.isin(compromised_terminals))]\n",
    "\n",
    "        transactions_df.loc[compromised_transactions.index,'TX_FRAUD']=1\n",
    "        transactions_df.loc[compromised_transactions.index,'TX_FRAUD_SCENARIO']=2\n",
    "\n",
    "    nb_frauds_scenario_2=transactions_df.TX_FRAUD.sum()-nb_frauds_scenario_1\n",
    "    print(\"Number of frauds from scenario 2: \"+str(nb_frauds_scenario_2))\n",
    "\n",
    "    # Scenario 3\n",
    "    for day in range(transactions_df.TX_TIME_DAYS.max()):\n",
    "\n",
    "        compromised_customers = customer_profiles_table.CUSTOMER_ID.sample(n=3, random_state=day).values\n",
    "\n",
    "        compromised_transactions=transactions_df[(transactions_df.TX_TIME_DAYS>=day) &\n",
    "                                                    (transactions_df.TX_TIME_DAYS<day+14) &\n",
    "                                                    (transactions_df.CUSTOMER_ID.isin(compromised_customers))]\n",
    "\n",
    "        nb_compromised_transactions=len(compromised_transactions)\n",
    "\n",
    "\n",
    "        random.seed(day)\n",
    "        index_fauds = random.sample(list(compromised_transactions.index.values),k=int(nb_compromised_transactions/3))\n",
    "\n",
    "        transactions_df.loc[index_fauds,'TX_AMOUNT']=transactions_df.loc[index_fauds,'TX_AMOUNT']*5\n",
    "        transactions_df.loc[index_fauds,'TX_FRAUD']=1\n",
    "        transactions_df.loc[index_fauds,'TX_FRAUD_SCENARIO']=3\n",
    "\n",
    "\n",
    "    nb_frauds_scenario_3=transactions_df.TX_FRAUD.sum()-nb_frauds_scenario_2-nb_frauds_scenario_1\n",
    "    print(\"Number of frauds from scenario 3: \"+str(nb_frauds_scenario_3))\n",
    "\n",
    "    return transactions_df\n",
    "\n",
    "\n",
    "(customer_profiles_table, terminal_profiles_table, transactions_df)=\\\n",
    "    generate_dataset_parallel(n_customers = 1000,\n",
    "                     n_terminals = 1000,\n",
    "                     nb_days=90,\n",
    "                     start_date=\"2024-01-01\",\n",
    "                     r=5)\n",
    "\n",
    "transactions_df = add_frauds(customer_profiles_table, terminal_profiles_table, transactions_df)\n",
    "\n",
    "dir_path = \"data_csv/\"\n",
    "customer_profiles_table.to_csv(dir_path + \"customers.csv\", index=False)\n",
    "terminal_profiles_table.to_csv(dir_path + \"terminals.csv\", index=False)\n",
    "transactions_df.to_csv(dir_path + \"transactions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inforet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
